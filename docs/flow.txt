一  第一阶段

数据总目录：/home/bavon/datasets/wsi/hsil

1 规整文件命名以及xml拷贝
  data_prepare.py 的 align_xml_svs 方法

2 生成normal切片（默认level1）
  create_patches_fp.py
  --source /home/liang/dataset/wsi/hsil --save_dir /home/liang/dataset/wsi/hsil --step_size 128 --patch_size 128  --patch_level 1 --seg --patch --stitch 
  输入目录 data 输出目录 patches_level1 ,输出内容包括多个h5文件，以及process_list_autogen.csv

3 xml标注文件转json 
  utexml2json2.py
	
4 生成训练和测试数据对照表 csv
  data_prepare.py 的 build_data_csv 方法
  
5 生成标注对应的图片patch
  data_prepare.py 的 crop_with_annotation 以及 build_annotation_patches (目标检测版本使用build_annotation_patches) 方法  
  输出目录 tumor_patch_img

6 训练
  train_with_clamdata.py    
    
对于normal类型，适用 2,6

二 一阶段测试及推理
1 生成推理结果
 came_inference.py main 方法
    --mode lsil --slide_size 128
     
2 可视化
  came_inference.py viz_results 方法

    
三 第二阶段

1 生成patch特征值
  extract_features_fp.py
  参数 --data_dir /home/bavon/datasets/wsi --types 'hsil','lsil' --feat_dir /home/bavon/datasets/wsi/combine/features --batch_size 256 --slide_ext .svs
  输出目录 /home/bavon/datasets/wsi/combine/features

2 合并生成训练和测试数据对照表 csv
  data_prepare.py 的 combine_mul_dataset_csv 方法
  
3 训练
  clam/main.py
  --drop_out  --lr 1e-4 --k 10 --label_frac 0.5 --exp_code task_1_tumor_vs_normal_CLAM_50 --weighted_sample --bag_loss ce --inst_loss svm --task task_1_tumor_vs_normal --model_type clam_sb --log_data --data_dir /home/bavon/datasets/wsi/combine --results_dir results/combine
  
  
  
  
  
  
  
